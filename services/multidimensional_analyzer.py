"""
å¤šç»´åº¦å­¦ä¹ å¼•æ“ - å…¨æ–¹ä½åˆ†æç”¨æˆ·ç‰¹å¾å’Œç¤¾äº¤å…³ç³»
"""
import re
import json
import time
import asyncio # ç¡®ä¿ asyncio å¯¼å…¥
from typing import Dict, List, Optional, Any, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import emoji # å¯¼å…¥ emoji åº“

from astrbot.api import logger
from astrbot.api.event import AstrMessageEvent

from ..config import PluginConfig
from ..exceptions import StyleAnalysisError
from ..core.llm_client import LLMClient # å¯¼å…¥è‡ªå®šä¹‰LLMClient
from .database_manager import DatabaseManager # å¯¼å…¥ DatabaseManager


@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    qq_id: str
    qq_name: str
    nicknames: List[str] = None
    activity_pattern: Dict[str, Any] = None
    communication_style: Dict[str, float] = None
    social_connections: List[str] = None
    topic_preferences: Dict[str, float] = None
    emotional_tendency: Dict[str, float] = None
    
    def __post_init__(self):
        if self.nicknames is None:
            self.nicknames = []
        if self.activity_pattern is None:
            self.activity_pattern = {}
        if self.communication_style is None:
            self.communication_style = {}
        if self.social_connections is None:
            self.social_connections = []
        if self.topic_preferences is None:
            self.topic_preferences = {}
        if self.emotional_tendency is None:
            self.emotional_tendency = {}


@dataclass
class SocialRelation:
    """ç¤¾äº¤å…³ç³»"""
    from_user: str
    to_user: str
    relation_type: str  # mention, reply, frequent_interaction
    strength: float  # å…³ç³»å¼ºåº¦ 0-1
    frequency: int   # äº¤äº’é¢‘æ¬¡
    last_interaction: str


@dataclass
class ContextualPattern:
    """æƒ…å¢ƒæ¨¡å¼"""
    context_type: str  # time_based, topic_based, social_based
    pattern_name: str
    triggers: List[str]
    characteristics: Dict[str, Any]
    confidence: float


class MultidimensionalAnalyzer:
    """å¤šç»´åº¦åˆ†æå™¨"""
    
    def __init__(self, config: PluginConfig, db_manager: DatabaseManager, context=None,
                 filter_llm_client: Optional[LLMClient] = None,
                 refine_llm_client: Optional[LLMClient] = None,
                 reinforce_llm_client: Optional[LLMClient] = None,
                 prompts: Any = None): # æ·»åŠ  prompts å‚æ•°
        self.config = config
        self.context = context
        self.db_manager: DatabaseManager = db_manager # ç›´æ¥ä¼ å…¥ DatabaseManager å®ä¾‹
        
        # LLM å®¢æˆ·ç«¯é€šè¿‡å‚æ•°ä¼ å…¥
        self.filter_llm_client = filter_llm_client
        self.refine_llm_client = refine_llm_client
        self.reinforce_llm_client = reinforce_llm_client
        self.prompts = prompts # ä¿å­˜ prompts

        if not (self.filter_llm_client and config.filter_api_url and config.filter_api_key and config.filter_model_name):
            logger.warning(f"ç­›é€‰æ¨¡å‹LLMé…ç½®ä¸å®Œæ•´ï¼šAPI URL: {config.filter_api_url}, API Key: {'***' if config.filter_api_key else 'None'}, Model Name: {config.filter_model_name}ã€‚å°†æ— æ³•ä½¿ç”¨LLMè¿›è¡Œæ¶ˆæ¯ç­›é€‰ã€‚")

        if not (self.refine_llm_client and config.refine_api_url and config.refine_api_key and config.refine_model_name):
            logger.warning(f"æç‚¼æ¨¡å‹LLMé…ç½®ä¸å®Œæ•´ï¼šAPI URL: {config.refine_api_url}, API Key: {'***' if config.refine_api_key else 'None'}, Model Name: {config.refine_model_name}ã€‚å°†æ— æ³•ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æã€‚")

        if not (self.reinforce_llm_client and config.reinforce_api_url and config.reinforce_api_key and config.reinforce_model_name):
            logger.warning(f"å¼ºåŒ–æ¨¡å‹LLMé…ç½®ä¸å®Œæ•´ï¼šAPI URL: {config.reinforce_api_url}, API Key: {'***' if config.reinforce_api_key else 'None'}, Model Name: {config.reinforce_model_name}ã€‚å°†æ— æ³•ä½¿ç”¨LLMè¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚")
        
        # ç”¨æˆ·ç”»åƒå­˜å‚¨
        self.user_profiles: Dict[str, UserProfile] = {}
        
        # ç¤¾äº¤å…³ç³»å›¾è°±
        self.social_graph: Dict[str, List[SocialRelation]] = defaultdict(list)
        
        # æ˜µç§°æ˜ å°„è¡¨
        self.nickname_mapping: Dict[str, str] = {}  # nickname -> qq_id
        
        # æƒ…å¢ƒæ¨¡å¼åº“
        self.contextual_patterns: List[ContextualPattern] = []
        
        # è¯é¢˜åˆ†ç±»å™¨
        self.topic_keywords = {
            'æ—¥å¸¸èŠå¤©': ['åƒé¥­', 'ç¡è§‰', 'ä¸Šç­', 'ä¸‹ç­', 'ä¼‘æ¯', 'å¿™'],
            'æ¸¸æˆå¨±ä¹': ['æ¸¸æˆ', 'ç”µå½±', 'éŸ³ä¹', 'å°è¯´', 'åŠ¨æ¼«', 'ç»¼è‰º'],
            'å­¦ä¹ å·¥ä½œ': ['å­¦ä¹ ', 'å·¥ä½œ', 'é¡¹ç›®', 'è€ƒè¯•', 'ä¼šè®®', 'ä»»åŠ¡'],
            'æƒ…æ„Ÿäº¤æµ': ['å¼€å¿ƒ', 'éš¾è¿‡', 'ç”Ÿæ°”', 'æ‹…å¿ƒ', 'å…´å¥‹', 'æ— èŠ'],
            'æŠ€æœ¯è®¨è®º': ['ä»£ç ', 'ç¨‹åº', 'ç®—æ³•', 'æŠ€æœ¯', 'å¼€å‘', 'ç¼–ç¨‹'],
            'ç”Ÿæ´»åˆ†äº«': ['æ—…æ¸¸', 'ç¾é£Ÿ', 'è´­ç‰©', 'å¥èº«', 'å® ç‰©', 'å®¶åº­']
        }
        
        logger.info("å¤šç»´åº¦å­¦ä¹ å¼•æ“åˆå§‹åŒ–å®Œæˆ")

    async def start(self):
        """æœåŠ¡å¯åŠ¨æ—¶åŠ è½½ç”¨æˆ·ç”»åƒå’Œç¤¾äº¤å…³ç³»"""
        # å‡è®¾æ¯ä¸ªç¾¤ç»„æœ‰ç‹¬ç«‹çš„ç”»åƒå’Œå…³ç³»ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ª group_id
        # ä¸ºäº†ç®€åŒ–ï¼Œæš‚æ—¶å‡è®¾åŠ è½½ä¸€ä¸ªé»˜è®¤çš„æˆ–å…¨å±€çš„ç”»åƒå’Œå…³ç³»
        # å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å½“å‰å¤„ç†çš„ç¾¤ç»„IDæ¥åŠ è½½
        default_group_id = "global_profiles" # æˆ–è€…ä»é…ç½®ä¸­è·å–
        
        # åŠ è½½æ‰€æœ‰ç”¨æˆ·ç”»åƒ (è¿™é‡Œéœ€è¦ DatabaseManager æä¾› load_all_user_profiles æ–¹æ³•)
        # æš‚æ—¶åªåŠ è½½ä¸€ä¸ªç¤ºä¾‹ç”¨æˆ·
        # loaded_profile_data = await self.db_manager.load_user_profile(default_group_id, "example_qq_id")
        # if loaded_profile_data:
        #     self.user_profiles[loaded_profile_data['qq_id']] = UserProfile(**loaded_profile_data)
        #     logger.info(f"å·²ä»æ•°æ®åº“åŠ è½½ç”¨æˆ·ç”»åƒ: {loaded_profile_data['qq_id']}")
        
        # åŠ è½½æ‰€æœ‰ç¤¾äº¤å…³ç³» (è¿™é‡Œéœ€è¦ DatabaseManager æä¾› load_all_social_relations æ–¹æ³•)
        # loaded_social_graph = await self.db_manager.load_social_graph(default_group_id)
        # for relation_data in loaded_social_graph:
        #     relation = SocialRelation(**relation_data)
        #     self.social_graph[relation.from_user].append(relation)
        # logger.info(f"å·²ä»æ•°æ®åº“åŠ è½½ {len(loaded_social_graph)} æ¡ç¤¾äº¤å…³ç³»ã€‚")
        
        logger.info("å¤šç»´åº¦å­¦ä¹ å¼•æ“å¯åŠ¨ï¼Œå‡†å¤‡è¿›è¡Œåˆ†æã€‚")

    async def filter_message_with_llm(self, message_text: str, current_persona_description: str) -> bool:
        """
        ä½¿ç”¨ LLM å¯¹æ¶ˆæ¯è¿›è¡Œæ™ºèƒ½ç­›é€‰ï¼Œåˆ¤æ–­å…¶æ˜¯å¦ä¸å½“å‰äººæ ¼åŒ¹é…ã€ç‰¹å¾é²œæ˜ä¸”æœ‰å­¦ä¹ æ„ä¹‰ã€‚
        è¿”å› True è¡¨ç¤ºæ¶ˆæ¯é€šè¿‡ç­›é€‰ï¼ŒFalse è¡¨ç¤ºä¸é€šè¿‡ã€‚
        """
        if not (self.config.filter_api_url and self.config.filter_api_key and self.config.filter_model_name):
            logger.warning("ç­›é€‰æ¨¡å‹LLMé…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡LLMæ¶ˆæ¯ç­›é€‰ã€‚")
            return True

        prompt = self.prompts.MULTIDIMENSIONAL_ANALYZER_FILTER_MESSAGE_PROMPT.format(
            current_persona_description=current_persona_description,
            message_text=message_text
        )
        try:
            response = await self.filter_llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.filter_api_url,
                api_key=self.config.filter_api_key,
                model_name=self.config.filter_model_name
            )
            if response and response.text():
                numbers = re.findall(r'0\.\d+|1\.0|0', response.text().strip())
                if numbers:
                    confidence = min(float(numbers[0]), 1.0)
                    logger.debug(f"æ¶ˆæ¯ç­›é€‰ç½®ä¿¡åº¦: {confidence} (é˜ˆå€¼: {self.config.confidence_threshold})")
                    return confidence >= self.config.confidence_threshold
            logger.warning(f"LLMç­›é€‰æ¨¡å‹æœªè¿”å›æœ‰æ•ˆç½®ä¿¡åº¦ï¼Œæ¶ˆæ¯é»˜è®¤ä¸é€šè¿‡ç­›é€‰ã€‚")
            return False
        except Exception as e:
            logger.error(f"LLMæ¶ˆæ¯ç­›é€‰å¤±è´¥: {e}")
            return False

    async def evaluate_message_quality_with_llm(self, message_text: str, current_persona_description: str) -> Dict[str, float]:
        """
        ä½¿ç”¨ LLM å¯¹æ¶ˆæ¯è¿›è¡Œå¤šç»´åº¦é‡åŒ–è¯„åˆ†ã€‚
        è¯„åˆ†ç»´åº¦åŒ…æ‹¬ï¼šå†…å®¹è´¨é‡ã€ç›¸å…³æ€§ã€æƒ…æ„Ÿç§¯ææ€§ã€äº’åŠ¨æ€§ã€å­¦ä¹ ä»·å€¼ã€‚
        è¿”å›ä¸€ä¸ªåŒ…å«å„ç»´åº¦è¯„åˆ†çš„å­—å…¸ã€‚
        """
        if not (self.config.refine_api_url and self.config.refine_api_key and self.config.refine_model_name):
            logger.warning("æç‚¼æ¨¡å‹LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMè¿›è¡Œå¤šç»´åº¦é‡åŒ–è¯„åˆ†ã€‚")
            return {
                "content_quality": 0.5,
                "relevance": 0.5,
                "emotional_positivity": 0.5,
                "interactivity": 0.5,
                "learning_value": 0.5
            }

        prompt = self.prompts.MULTIDIMENSIONAL_ANALYZER_EVALUATE_MESSAGE_QUALITY_PROMPT.format(
            current_persona_description=current_persona_description,
            message_text=message_text
        )
        try:
            response = await self.refine_llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.refine_api_url,
                api_key=self.config.refine_api_key,
                model_name=self.config.refine_model_name
            )
            if response and response.text():
                try:
                    scores = json.loads(response.text().strip())
                    # ç¡®ä¿æ‰€æœ‰åˆ†æ•°éƒ½åœ¨0-1ä¹‹é—´
                    for key, value in scores.items():
                        scores[key] = max(0.0, min(float(value), 1.0))
                    logger.debug(f"æ¶ˆæ¯å¤šç»´åº¦è¯„åˆ†: {scores}")
                    return scores
                except json.JSONDecodeError:
                    logger.warning(f"LLMå¤šç»´åº¦è¯„åˆ†å“åº”JSONè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤è¯„åˆ†ã€‚å“åº”å†…å®¹: {response.text()}")
                    return {
                        "content_quality": 0.5,
                        "relevance": 0.5,
                        "emotional_positivity": 0.5,
                        "interactivity": 0.5,
                        "learning_value": 0.5
                    }
            logger.warning(f"LLMå¤šç»´åº¦è¯„åˆ†æ¨¡å‹æœªè¿”å›æœ‰æ•ˆå“åº”ï¼Œè¿”å›é»˜è®¤è¯„åˆ†ã€‚")
            return {
                "content_quality": 0.5,
                "relevance": 0.5,
                "emotional_positivity": 0.5,
                "interactivity": 0.5,
                "learning_value": 0.5
            }
        except Exception as e:
            logger.error(f"LLMå¤šç»´åº¦è¯„åˆ†å¤±è´¥: {e}")
            return {
                "content_quality": 0.5,
                "relevance": 0.5,
                "emotional_positivity": 0.5,
                "interactivity": 0.5,
                "learning_value": 0.5
            }

    async def analyze_message_context(self, event: AstrMessageEvent, message_text: str) -> Dict[str, Any]:
        """åˆ†ææ¶ˆæ¯çš„å¤šç»´åº¦ä¸Šä¸‹æ–‡"""
        try:
            sender_id = event.get_sender_id()
            sender_name = event.get_sender_name()
            group_id = event.get_group_id()
            
            # æ›´æ–°ç”¨æˆ·ç”»åƒ
            await self._update_user_profile(group_id, sender_id, sender_name, message_text, event) # ä¼ å…¥ group_id
            
            # åˆ†æç¤¾äº¤å…³ç³»
            social_context = await self._analyze_social_context(event, message_text)
            
            # åˆ†æè¯é¢˜åå¥½
            topic_context = await self._analyze_topic_context(message_text)
            
            # åˆ†ææƒ…æ„Ÿå€¾å‘
            emotional_context = await self._analyze_emotional_context(message_text)
            
            # åˆ†ææ—¶é—´æ¨¡å¼
            temporal_context = await self._analyze_temporal_context(event)
            
            # åˆ†ææ²Ÿé€šé£æ ¼
            style_context = await self._analyze_communication_style(message_text)
            
            return {
                'user_profile': self.user_profiles.get(sender_id, {}).activity_pattern if sender_id in self.user_profiles else {},
                'social_context': social_context,
                'topic_context': topic_context,
                'emotional_context': emotional_context,
                'temporal_context': temporal_context,
                'style_context': style_context,
                'contextual_relevance': await self._calculate_contextual_relevance(
                    sender_id, message_text, event
                )
            }
            
        except Exception as e:
            logger.error(f"å¤šç»´åº¦ä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {e}")
            return {}

    async def _update_user_profile(self, group_id: str, qq_id: str, qq_name: str, message_text: str, event: AstrMessageEvent):
        """æ›´æ–°ç”¨æˆ·ç”»åƒå¹¶æŒä¹…åŒ–"""
        profile_data = await self.db_manager.load_user_profile(group_id, qq_id)
        if profile_data:
            profile = UserProfile(**profile_data)
        else:
            profile = UserProfile(qq_id=qq_id, qq_name=qq_name)
        
        # æ›´æ–°æ´»åŠ¨æ¨¡å¼
        current_hour = datetime.now().hour
        if 'activity_hours' not in profile.activity_pattern:
            profile.activity_pattern['activity_hours'] = Counter()
        profile.activity_pattern['activity_hours'][current_hour] += 1
        
        # æ›´æ–°æ¶ˆæ¯é•¿åº¦åå¥½
        msg_length = len(message_text)
        if 'message_lengths' not in profile.activity_pattern:
            profile.activity_pattern['message_lengths'] = []
        profile.activity_pattern['message_lengths'].append(msg_length)
        
        # ä¿æŒæœ€è¿‘100æ¡æ¶ˆæ¯çš„é•¿åº¦è®°å½•
        if len(profile.activity_pattern['message_lengths']) > 100:
            profile.activity_pattern['message_lengths'] = profile.activity_pattern['message_lengths'][-100:]
        
        # æ›´æ–°è¯é¢˜åå¥½
        topics = await self._extract_topics(message_text)
        for topic in topics:
            if topic not in profile.topic_preferences:
                profile.topic_preferences[topic] = 0
            profile.topic_preferences[topic] += 1
        
        # æ›´æ–°æ²Ÿé€šé£æ ¼
        style_features = await self._extract_style_features(message_text)
        for feature, value in style_features.items():
            if feature not in profile.communication_style:
                profile.communication_style[feature] = []
            profile.communication_style[feature].append(value)
            
            # ä¿æŒæœ€è¿‘50ä¸ªç‰¹å¾å€¼
            if len(profile.communication_style[feature]) > 50:
                profile.communication_style[feature] = profile.communication_style[feature][-50:]
        
        self.user_profiles[qq_id] = profile # æ›´æ–°å†…å­˜ä¸­çš„ç”»åƒ
        await self.db_manager.save_user_profile(group_id, asdict(profile)) # æŒä¹…åŒ–åˆ°æ•°æ®åº“

    async def _analyze_social_context(self, event: AstrMessageEvent, message_text: str) -> Dict[str, Any]:
        """åˆ†æç¤¾äº¤å…³ç³»ä¸Šä¸‹æ–‡"""
        try:
            sender_id = event.get_sender_id()
            group_id = event.get_group_id()
            
            social_context = {
                'mentions': [],
                'replies': [],
                'interaction_strength': {},
                'group_role': 'member'
            }
            
            # æå–@æ¶ˆæ¯
            mentions = self._extract_mentions(message_text)
            social_context['mentions'] = mentions
            
            # æ›´æ–°ç¤¾äº¤å…³ç³»
            for mentioned_user in mentions:
                await self._update_social_relation(
                    sender_id, mentioned_user, 'mention', group_id
                )
            
            # åˆ†æå›å¤å…³ç³»ï¼ˆå¦‚æœæ¡†æ¶æ”¯æŒï¼‰
            if hasattr(event, 'get_reply_info') and event.get_reply_info():
                reply_info = event.get_reply_info()
                replied_user = reply_info.get('user_id')
                if replied_user:
                    social_context['replies'].append(replied_user)
                    await self._update_social_relation(
                        sender_id, replied_user, 'reply', group_id
                    )
            
            # è®¡ç®—ä¸ç¾¤å†…æˆå‘˜çš„äº¤äº’å¼ºåº¦
            if sender_id in self.social_graph:
                for relation in self.social_graph[sender_id]:
                    social_context['interaction_strength'][relation.to_user] = relation.strength
            
            # åˆ†æç¾¤å†…è§’è‰²ï¼ˆåŸºäºå‘è¨€é¢‘ç‡å’Œ@æ¬¡æ•°ï¼‰
            group_role = await self._analyze_group_role(sender_id, group_id)
            social_context['group_role'] = group_role
            
            return social_context
        
        except Exception as e:
            logger.warning(f"ç¤¾äº¤ä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {e}")
            return {}

    async def _analyze_topic_context(self, message_text: str) -> Dict[str, float]:
        """åˆ†æè¯é¢˜ä¸Šä¸‹æ–‡"""
        topic_scores = {}
        
        for topic, keywords in self.topic_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in message_text:
                    score += 1
            
            if score > 0:
                topic_scores[topic] = score / len(keywords)
        
        return topic_scores

    async def _analyze_emotional_context(self, message_text: str) -> Dict[str, float]:
        """ä½¿ç”¨LLMåˆ†ææƒ…æ„Ÿä¸Šä¸‹æ–‡"""
        if not (self.config.refine_api_url and self.config.refine_api_key and self.config.refine_model_name):
            logger.warning("æç‚¼æ¨¡å‹LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMåˆ†ææƒ…æ„Ÿä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•ã€‚")
            return self._simple_emotional_analysis(message_text)

        try:
            prompt = self.prompts.MULTIDIMENSIONAL_ANALYZER_EMOTIONAL_CONTEXT_PROMPT.format(
                message_text=message_text
            )
            try:
                response = await self.refine_llm_client.chat_completion(
                    prompt=prompt,
                    api_url=self.config.refine_api_url,
                    api_key=self.config.refine_api_key,
                    model_name=self.config.refine_model_name
                )
                
                if response and response.text():
                    try:
                        emotion_scores = json.loads(response.text().strip())
                        # ç¡®ä¿æ‰€æœ‰åˆ†æ•°éƒ½åœ¨0-1ä¹‹é—´
                        for key, value in emotion_scores.items():
                            emotion_scores[key] = max(0.0, min(float(value), 1.0))
                        return emotion_scores
                    except json.JSONDecodeError:
                        logger.warning(f"LLMå“åº”JSONè§£æå¤±è´¥ï¼Œè¿”å›ç®€åŒ–æƒ…æ„Ÿåˆ†æã€‚å“åº”å†…å®¹: {response.text()}")
                        return self._simple_emotional_analysis(message_text)
                return self._simple_emotional_analysis(message_text)
                
            except Exception as e:
                logger.warning(f"LLMæƒ…æ„Ÿåˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•: {e}")
        except Exception as e:
            logger.warning(f"LLMæƒ…æ„Ÿåˆ†æå¤±è´¥ - 2ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•: {e}")


    def _simple_emotional_analysis(self, message_text: str) -> Dict[str, float]:
        """ç®€åŒ–çš„æƒ…æ„Ÿåˆ†æï¼ˆå¤‡ç”¨ï¼‰"""
        emotions = {
            'ç§¯æ': ['å¼€å¿ƒ', 'é«˜å…´', 'å…´å¥‹', 'æ»¡æ„', 'å–œæ¬¢', 'çˆ±', 'å¥½æ£’', 'å¤ªå¥½äº†', 'å“ˆå“ˆ', 'ğŸ˜„', 'ğŸ˜Š', 'ğŸ‘'],
            'æ¶ˆæ': ['éš¾è¿‡', 'ç”Ÿæ°”', 'å¤±æœ›', 'æ— èŠ', 'çƒ¦', 'è®¨åŒ', 'ç³Ÿç³•', 'ä¸å¥½', 'ğŸ˜­', 'ğŸ˜¢', 'ğŸ˜¡'],
            'ä¸­æ€§': ['çŸ¥é“', 'æ˜ç™½', 'å¯ä»¥', 'å¥½çš„', 'å—¯', 'å“¦', 'è¿™æ ·', 'ç„¶å'],
            'ç–‘é—®': ['å—', 'å‘¢', 'ï¼Ÿ', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'ğŸ¤”'],
            'æƒŠè®¶': ['å“‡', 'å¤©å“ª', 'çœŸçš„', 'ä¸ä¼šå§', 'å¤ª', 'ç«Ÿç„¶', 'å±…ç„¶', 'ğŸ˜±', 'ğŸ˜¯']
        }
        
        emotion_scores = {}
        # å°†æ¶ˆæ¯æ–‡æœ¬æŒ‰ç©ºæ ¼æˆ–æ ‡ç‚¹ç¬¦å·åˆ†å‰²æˆå•è¯ï¼Œå¹¶è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²
        words = [word for word in re.split(r'\s+|[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š]', message_text) if word]
        total_words = len(words) # å·²ç»ä¿®æ”¹ä¸ºå•è¯æ€»æ•°
        
        for emotion, keywords in emotions.items():
            count = 0
            for keyword in keywords:
                # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨å•è¯åˆ—è¡¨ä¸­
                count += words.count(keyword)
            
            emotion_scores[emotion] = count / max(total_words, 1)
        
        return emotion_scores

    async def _analyze_temporal_context(self, event: AstrMessageEvent) -> Dict[str, Any]:
        """åˆ†ææ—¶é—´ä¸Šä¸‹æ–‡"""
        now = datetime.now()
        
        time_context = {
            'hour': now.hour,
            'weekday': now.weekday(),
            'time_period': self._get_time_period(now.hour),
            'is_weekend': now.weekday() >= 5,
            'season': self._get_season(now.month)
        }
        
        return time_context

    async def _analyze_communication_style(self, message_text: str) -> Dict[str, float]:
        """åˆ†ææ²Ÿé€šé£æ ¼"""
        style_features = {
            'formal_level': self._calculate_formal_level(message_text),
            'enthusiasm_level': self._calculate_enthusiasm_level(message_text),
            'question_tendency': self._calculate_question_tendency(message_text),
            'emoji_usage': self._calculate_emoji_usage(message_text),
            'length_preference': len(message_text),
            'punctuation_style': self._calculate_punctuation_style(message_text)
        }
        
        return style_features

    async def _extract_topics(self, message_text: str) -> List[str]:
        """æå–æ¶ˆæ¯è¯é¢˜"""
        detected_topics = []
        
        for topic, keywords in self.topic_keywords.items():
            for keyword in keywords:
                if keyword in message_text:
                    detected_topics.append(topic)
                    break
        
        return detected_topics

    async def _extract_style_features(self, message_text: str) -> Dict[str, float]:
        """æå–é£æ ¼ç‰¹å¾"""
        return {
            'length': len(message_text),
            'punctuation_ratio': len([c for c in message_text if c in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š']) / max(len(message_text), 1),
            'emoji_count': emoji.emoji_count(message_text),
            'question_count': message_text.count('ï¼Ÿ') + message_text.count('?'),
            'exclamation_count': message_text.count('ï¼') + message_text.count('!')
        }

    def _extract_mentions(self, message_text: str) -> List[str]:
        """æå–@æ¶ˆæ¯"""
        # åŒ¹é…@ç”¨æˆ·æ¨¡å¼
        at_pattern = r'@(\w+|\d+)'
        matches = re.findall(at_pattern, message_text)
        
        # å°è¯•è§£ææ˜µç§°åˆ°QQå·çš„æ˜ å°„
        mentioned_users = []
        for match in matches:
            if match.isdigit():
                # ç›´æ¥@çš„QQå·
                mentioned_users.append(match)
            else:
                # @çš„æ˜µç§°ï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”çš„QQå·
                if match in self.nickname_mapping:
                    mentioned_users.append(self.nickname_mapping[match])
                else:
                    # è®°å½•æœªçŸ¥æ˜µç§°
                    mentioned_users.append(f"nickname:{match}")
        
        return mentioned_users

    async def _update_social_relation(self, from_user: str, to_user: str, relation_type: str, group_id: str):
        """æ›´æ–°ç¤¾äº¤å…³ç³»"""
        # æŸ¥æ‰¾ç°æœ‰å…³ç³»
        existing_relation = None
        for relation in self.social_graph[from_user]:
            if relation.to_user == to_user and relation.relation_type == relation_type:
                existing_relation = relation
                break
        
        if existing_relation:
            # æ›´æ–°ç°æœ‰å…³ç³»
            existing_relation.frequency += 1
            existing_relation.last_interaction = datetime.now().isoformat()
            existing_relation.strength = min(existing_relation.strength + 0.1, 1.0)
        else:
            # åˆ›å»ºæ–°å…³ç³»
            new_relation = SocialRelation(
                from_user=from_user,
                to_user=to_user,
                relation_type=relation_type,
                strength=0.1,
                frequency=1,
                last_interaction=datetime.now().isoformat()
            )
            self.social_graph[from_user].append(new_relation)
        
        # æŒä¹…åŒ–ç¤¾äº¤å…³ç³»
        await self.db_manager.save_social_relation(group_id, asdict(existing_relation if existing_relation else new_relation))

    async def _analyze_group_role(self, user_id: str, group_id: str) -> str:
        """åˆ†æç”¨æˆ·åœ¨ç¾¤å†…çš„è§’è‰²"""
        # è¿™é‡Œå¯ä»¥åŸºäºå‘è¨€é¢‘ç‡ã€è¢«@æ¬¡æ•°ç­‰åˆ¤æ–­ç”¨æˆ·è§’è‰²
        # ç®€åŒ–å®ç°
        if user_id in self.user_profiles:
            profile = self.user_profiles[user_id]
            mention_count = sum(1 for relations in self.social_graph.values() 
                              for relation in relations 
                              if relation.to_user == user_id and relation.relation_type == 'mention')
            
            if mention_count > 10:
                return 'active_member'
            elif mention_count > 5:
                return 'regular_member'
            else:
                return 'member'
        
        return 'member'

    async def _calculate_contextual_relevance(self, sender_id: str, message_text: str, event: AstrMessageEvent) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§å¾—åˆ†"""
        relevance_score = 0.0
        
        # åŸºäºç”¨æˆ·å†å²è¡Œä¸ºçš„ç›¸å…³æ€§
        if sender_id in self.user_profiles:
            profile = self.user_profiles[sender_id]
            
            # è¯é¢˜ä¸€è‡´æ€§
            current_topics = await self._extract_topics(message_text)
            for topic in current_topics:
                if topic in profile.topic_preferences:
                    relevance_score += 0.2
            
            # é£æ ¼ä¸€è‡´æ€§
            current_style = await self._extract_style_features(message_text)
            if 'length' in profile.communication_style:
                avg_length = sum(profile.communication_style['length'][-10:]) / min(10, len(profile.communication_style['length']))
                length_similarity = 1.0 - abs(current_style['length'] - avg_length) / max(avg_length, 1)
                relevance_score += length_similarity * 0.1
        
            # æ—¶é—´ä¸Šä¸‹æ–‡ç›¸å…³æ€§
            current_hour = datetime.now().hour
            if sender_id in self.user_profiles:
                profile = self.user_profiles[sender_id]
                if 'activity_hours' in profile.activity_pattern:
                    hour_frequency = profile.activity_pattern['activity_hours'].get(current_hour, 0)
                    total_messages = sum(profile.activity_pattern['activity_hours'].values())
                    if total_messages > 0:
                        time_relevance = hour_frequency / total_messages
                        relevance_score += time_relevance * 0.2
        
        return min(relevance_score, 1.0)

    def _get_time_period(self, hour: int) -> str:
        """è·å–æ—¶é—´æ®µ"""
        if 6 <= hour < 12:
            return 'ä¸Šåˆ'
        elif 12 <= hour < 18:
            return 'ä¸‹åˆ'
        elif 18 <= hour < 22:
            return 'æ™šä¸Š'
        else:
            return 'æ·±å¤œ'

    def _get_season(self, month: int) -> str:
        """è·å–å­£èŠ‚"""
        if month in [1, 2, 12]:
            return 'å†¬å­£'
        elif month in [3, 4, 5]:
            return 'æ˜¥å­£'
        elif month in [6, 7, 8]:
            return 'å¤å­£'
        else:
            return 'ç§‹å­£'

    async def _call_llm_for_style_analysis(self, text: str, prompt_template: str, fallback_function: callable, analysis_name: str) -> float:
        """
        é€šç”¨çš„LLMé£æ ¼åˆ†æè¾…åŠ©å‡½æ•°ã€‚
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬ã€‚
            prompt_template: LLMæç¤ºæ¨¡æ¿ã€‚
            fallback_function: LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–æˆ–è°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨çš„å¤‡ç”¨å‡½æ•°ã€‚
            analysis_name: åˆ†æåç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•ã€‚
        Returns:
            0-1ä¹‹é—´çš„è¯„åˆ†ã€‚
        """
        if not (self.config.refine_api_url and self.config.refine_api_key and self.config.refine_model_name):
            logger.warning(f"æç‚¼æ¨¡å‹LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMè®¡ç®—{analysis_name}ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•ã€‚")
            return fallback_function(text)

        try:
            prompt = prompt_template.format(text=text)
            response = await self.refine_llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.refine_api_url,
                api_key=self.config.refine_api_key,
                model_name=self.config.refine_model_name
            )
            
            if response and response.text():
                numbers = re.findall(r'0\.\d+|1\.0|0', response.text().strip())
                if numbers:
                    return min(float(numbers[0]), 1.0)
            
            return 0.5 # é»˜è®¤å€¼
            
        except Exception as e:
            logger.warning(f"LLM{analysis_name}è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•: {e}")
            return fallback_function(text)

    async def _calculate_formal_level(self, text: str) -> float:
        """ä½¿ç”¨LLMè®¡ç®—æ­£å¼ç¨‹åº¦"""
        prompt_template = self.prompts.MULTIDIMENSIONAL_ANALYZER_FORMAL_LEVEL_PROMPT
        return await self._call_llm_for_style_analysis(text, prompt_template, self._simple_formal_level, "æ­£å¼ç¨‹åº¦")

    def _simple_formal_level(self, text: str) -> float:
        """ç®€åŒ–çš„æ­£å¼ç¨‹åº¦è®¡ç®—ï¼ˆå¤‡ç”¨ï¼‰"""
        formal_indicators = ['æ‚¨', 'è¯·', 'è°¢è°¢æ‚¨', 'ä¸å¥½æ„æ€', 'æ‰“æ‰°äº†', 'æ•æˆ‘ç›´è¨€', 'è¯·é—®']
        informal_indicators = ['å“ˆå“ˆ', 'å˜¿', 'å•Š', 'å‘€', 'å“¦', 'å—¯å—¯', 'å“‡']
        
        formal_count = sum(text.count(word) for word in formal_indicators)
        informal_count = sum(text.count(word) for word in informal_indicators)
        
        total = formal_count + informal_count
        return formal_count / max(total, 1) if total > 0 else 0.5

    async def _calculate_enthusiasm_level(self, text: str) -> float:
        """ä½¿ç”¨LLMè®¡ç®—çƒ­æƒ…ç¨‹åº¦"""
        prompt_template = self.prompts.MULTIDIMENSIONAL_ANALYZER_ENTHUSIASM_LEVEL_PROMPT
        return await self._call_llm_for_style_analysis(text, prompt_template, self._simple_enthusiasm_level, "çƒ­æƒ…ç¨‹åº¦")

    def _simple_enthusiasm_level(self, text: str) -> float:
        """ç®€åŒ–çš„çƒ­æƒ…ç¨‹åº¦è®¡ç®—ï¼ˆå¤‡ç”¨ï¼‰"""
        enthusiasm_indicators = ['ï¼', '!', 'å“ˆå“ˆ', 'å¤ªå¥½äº†', 'æ£’', 'èµ', 'ğŸ˜„', 'ğŸ˜Š', 'ğŸ‰', 'å‰å®³', 'awesome']
        count = sum(text.count(indicator) for indicator in enthusiasm_indicators)
        return min(count / max(len(text), 1) * 20, 1.0)

    async def _calculate_question_tendency(self, text: str) -> float:
        """ä½¿ç”¨LLMè®¡ç®—æé—®å€¾å‘"""
        prompt_template = self.prompts.MULTIDIMENSIONAL_ANALYZER_QUESTION_TENDENCY_PROMPT
        return await self._call_llm_for_style_analysis(text, prompt_template, self._simple_question_tendency, "æé—®å€¾å‘")

    def _simple_question_tendency(self, text: str) -> float:
        """ç®€åŒ–çš„æé—®å€¾å‘è®¡ç®—ï¼ˆå¤‡ç”¨ï¼‰"""
        question_indicators = ['ï¼Ÿ', '?', 'å—', 'å‘¢', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'å¦‚ä½•']
        count = sum(text.count(indicator) for indicator in question_indicators)
        return min(count / max(len(text), 1) * 10, 1.0)

    def _calculate_emoji_usage(self, text: str) -> float:
        """è®¡ç®—è¡¨æƒ…ç¬¦å·ä½¿ç”¨ç¨‹åº¦"""
        emoji_count = emoji.emoji_count(text)
        return min(emoji_count / max(len(text), 1) * 10, 1.0)

    def _calculate_punctuation_style(self, text: str) -> float:
        """è®¡ç®—æ ‡ç‚¹ç¬¦å·é£æ ¼"""
        punctuation_count = len([c for c in text if c in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''()ï¼ˆï¼‰'])
        return punctuation_count / max(len(text), 1)

    async def get_user_insights(self, qq_id: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMç”Ÿæˆæ·±åº¦ç”¨æˆ·æ´å¯Ÿ"""
        if qq_id not in self.user_profiles:
            return {"error": "ç”¨æˆ·ä¸å­˜åœ¨"}
        
        profile = self.user_profiles[qq_id]
        
        # è®¡ç®—æ´»è·ƒæ—¶æ®µ
        active_hours = []
        if 'activity_hours' in profile.activity_pattern:
            sorted_hours = sorted(profile.activity_pattern['activity_hours'].items(), 
                                key=lambda x: x[1], reverse=True) # ä¿®æ­£æ’åºé”®
            active_hours = [hour for hour, count in sorted_hours[:3]]
        
        # è®¡ç®—ä¸»è¦è¯é¢˜
        main_topics = sorted(profile.topic_preferences.items(), 
                           key=lambda x: x[1], reverse=True)[:3] # ä¿®æ­£æ’åºé”®
        
        # è®¡ç®—ç¤¾äº¤æ´»è·ƒåº¦
        social_activity = len(self.social_graph.get(qq_id, []))
        
        # ä½¿ç”¨LLMç”Ÿæˆæ·±åº¦æ´å¯Ÿ
        deep_insights = await self._generate_deep_insights(profile)
        
        return {
            'user_id': qq_id,
            'user_name': profile.qq_name,
            'nicknames': profile.nicknames,
            'active_hours': active_hours,
            'main_topics': [topic for topic, count in main_topics],
            'social_activity': social_activity,
            'communication_style_summary': self._summarize_communication_style(profile),
            'activity_summary': self._summarize_activity_pattern(profile),
            'deep_insights': deep_insights,
            'personality_analysis': await self._analyze_personality_traits(profile),
            'social_behavior': await self._analyze_social_behavior(qq_id)
        }

    async def _generate_deep_insights(self, profile: UserProfile) -> Dict[str, Any]:
        """ä½¿ç”¨LLMç”Ÿæˆæ·±åº¦ç”¨æˆ·æ´å¯Ÿ"""
        if not (self.config.refine_api_url and self.config.refine_api_key and self.config.refine_model_name):
            logger.warning("æç‚¼æ¨¡å‹LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMç”Ÿæˆæ·±åº¦ç”¨æˆ·æ´å¯Ÿã€‚")
            return {"error": "LLMæœåŠ¡ä¸å¯ç”¨"}

        try:
            # å‡†å¤‡ç”¨æˆ·æ•°æ®æ‘˜è¦
            user_data_summary = {
                'qq_name': profile.qq_name,
                'nicknames': profile.nicknames,
                'topic_preferences': dict(list(profile.topic_preferences.items())[:5]),
                'activity_pattern': {
                    'peak_hours': [k for k, v in sorted(
                        profile.activity_pattern.get('activity_hours', {}).items(),
                        key=lambda item: item[1], reverse=True
                    )[:3]],
                    'avg_message_length': sum(profile.activity_pattern.get('message_lengths', [])) / 
                                        max(len(profile.activity_pattern.get('message_lengths', [])), 1)
                },
                'social_connections': len(profile.social_connections)
            }
            
            prompt = self.prompts.MULTIDIMENSIONAL_ANALYZER_DEEP_INSIGHTS_PROMPT.format(
                user_data_summary=json.dumps(user_data_summary, ensure_ascii=False, indent=2)
            )
            
            response = await self.refine_llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.refine_api_url,
                api_key=self.config.refine_api_key,
                model_name=self.config.refine_model_name
            )
            
            if response and response.text():
                try:
                    insights = json.loads(response.text().strip())
                    return insights
                except json.JSONDecodeError:
                    logger.warning(f"LLMå“åº”JSONè§£æå¤±è´¥ï¼Œè¿”å›ç®€åŒ–åˆ†æã€‚å“åº”å†…å®¹: {response.text()}")
                    return {
                        "personality_type": "åˆ†æä¸­",
                        "communication_preference": "å¾…æ·±å…¥åˆ†æ",
                        "social_role": "ç¾¤ä½“æˆå‘˜",
                        "learning_potential": 0.7
                    }
            return {"error": "LLMæœªè¿”å›æœ‰æ•ˆå“åº”"}
                
        except Exception as e:
            logger.warning(f"æ·±åº¦æ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            return {"error": "æ´å¯Ÿç”Ÿæˆå¤±è´¥"}

    async def _analyze_personality_traits(self, profile: UserProfile) -> Dict[str, float]:
        """åˆ†æç”¨æˆ·äººæ ¼ç‰¹è´¨"""
        if not (self.config.refine_api_url and self.config.refine_api_key and self.config.refine_model_name):
            logger.warning("æç‚¼æ¨¡å‹LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMåˆ†æäººæ ¼ç‰¹è´¨ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•ã€‚")
            return self._simple_personality_analysis(profile)

        try:
            # è·å–æœ€è¿‘çš„æ²Ÿé€šé£æ ¼æ•°æ®
            recent_styles = {}
            for feature, values in profile.communication_style.items():
                if values:
                    recent_styles[feature] = sum(values[-10:]) / min(len(values), 10)
            
            prompt = self.prompts.MULTIDIMENSIONAL_ANALYZER_PERSONALITY_TRAITS_PROMPT.format(
                communication_style_data=json.dumps(recent_styles, ensure_ascii=False, indent=2)
            )
            
            response = await self.refine_llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.refine_api_url,
                api_key=self.config.refine_api_key,
                model_name=self.config.refine_model_name
            )
            
            if response and response.text():
                try:
                    traits = json.loads(response.text().strip())
                    return traits
                except json.JSONDecodeError:
                    logger.warning(f"LLMå“åº”JSONè§£æå¤±è´¥ï¼Œè¿”å›ç®€åŒ–äººæ ¼åˆ†æã€‚å“åº”å†…å®¹: {response.text()}")
                    return self._simple_personality_analysis(profile)
            return self._simple_personality_analysis(profile)
                
        except Exception as e:
            logger.warning(f"äººæ ¼ç‰¹è´¨åˆ†æå¤±è´¥: {e}")
            return self._simple_personality_analysis(profile)

    def _simple_personality_analysis(self, profile: UserProfile) -> Dict[str, float]:
        """ç®€åŒ–çš„äººæ ¼åˆ†æï¼ˆå¤‡ç”¨ï¼‰"""
        # åŸºäºåŸºç¡€æ•°æ®çš„ç®€å•åˆ†æ
        style_data = profile.communication_style
        
        # å¤–å‘æ€§ï¼šåŸºäºæ¶ˆæ¯é¢‘ç‡å’Œé•¿åº¦
        extraversion = 0.5
        if 'length' in style_data and style_data['length']:
            avg_length = sum(style_data['length'][-20:]) / min(len(style_data['length']), 20)
            extraversion = min(avg_length / 100, 1.0)
        
        # å¼€æ”¾æ€§ï¼šåŸºäºè¯é¢˜å¤šæ ·æ€§
        openness = len(profile.topic_preferences) / 10 if profile.topic_preferences else 0.5
        
        return {
            "openness": min(openness, 1.0),
            "conscientiousness": 0.6,  # é»˜è®¤å€¼
            "extraversion": extraversion,
            "agreeableness": 0.7,  # é»˜è®¤å€¼
            "neuroticism": 0.3   # é»˜è®¤å€¼
        }

    async def _analyze_social_behavior(self, qq_id: str) -> Dict[str, Any]:
        """åˆ†æç¤¾äº¤è¡Œä¸ºæ¨¡å¼"""
        if qq_id not in self.social_graph:
            return {"interaction_count": 0, "relationship_strength": {}}
        
        relations = self.social_graph[qq_id]
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„ç¤¾äº¤è¡Œä¸º
        behavior_stats = {
            "mention_frequency": len([r for r in relations if r.relation_type == 'mention']),
            "reply_frequency": len([r for r in relations if r.relation_type == 'reply']),
            "total_interactions": len(relations),
            "avg_relationship_strength": sum(r.strength for r in relations) / max(len(relations), 1),
            "top_connections": [
                {"user": r.to_user, "strength": r.strength, "frequency": r.frequency}
                for r in sorted(relations, key=lambda x: x.strength, reverse=True)[:5]
            ]
        }
        
        return behavior_stats

    def _summarize_communication_style(self, profile: UserProfile) -> Dict[str, str]:
        """æ€»ç»“æ²Ÿé€šé£æ ¼"""
        style_summary = {}
        
        if 'length' in profile.communication_style and profile.communication_style['length']:
            avg_length = sum(profile.communication_style['length']) / len(profile.communication_style['length'])
            if avg_length > 50:
                style_summary['length_style'] = 'è¯¦ç»†å‹'
            elif avg_length > 20:
                style_summary['length_style'] = 'é€‚ä¸­å‹'
            else:
                style_summary['length_style'] = 'ç®€æ´å‹'
        
        return style_summary

    def _summarize_activity_pattern(self, profile: UserProfile) -> Dict[str, Any]:
        """æ€»ç»“æ´»åŠ¨æ¨¡å¼"""
        activity_summary = {}
        
        if 'activity_hours' in profile.activity_pattern:
            hours = profile.activity_pattern['activity_hours']
            if hours:
                peak_hour = max(hours.items(), key=lambda x: x[1])[0] # ä¿®æ­£ä¸ºè·å–é”®
                activity_summary['peak_hour'] = peak_hour
                activity_summary['peak_period'] = self._get_time_period(peak_hour)
        
        return activity_summary

    async def export_social_graph(self) -> Dict[str, Any]:
        """å¯¼å‡ºç¤¾äº¤å…³ç³»å›¾è°±"""
        graph_data = {
            'nodes': [],
            'edges': [],
            'statistics': {}
        }
        
        # å¯¼å‡ºèŠ‚ç‚¹ï¼ˆç”¨æˆ·ï¼‰
        # ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç”¨æˆ·ç”»åƒï¼Œè€Œä¸æ˜¯åªï¿½ï¿½ï¿½å†…å­˜ä¸­è·å–
        # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œä»ç„¶ä½¿ç”¨å†…å­˜ä¸­çš„ user_profilesï¼Œä½†å®é™…åº”è¯¥ä»æ•°æ®åº“åŠ è½½
        for qq_id, profile in self.user_profiles.items():
            graph_data['nodes'].append({
                'id': qq_id,
                'name': profile.qq_name,
                'nicknames': profile.nicknames,
                'activity_level': len(profile.activity_pattern.get('activity_hours', {}))
            })
        
        # å¯¼å‡ºè¾¹ï¼ˆå…³ç³»ï¼‰
        # ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç¤¾äº¤å…³ç³»ï¼Œè€Œä¸æ˜¯åªä»å†…å­˜ä¸­è·å–
        # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œä»ç„¶ä½¿ç”¨å†…å­˜ä¸­çš„ social_graphï¼Œä½†å®é™…åº”è¯¥ä»æ•°æ®åº“åŠ è½½
        for from_user, relations in self.social_graph.items():
            for relation in relations:
                graph_data['edges'].append({
                    'from': from_user,
                    'to': relation.to_user,
                    'type': relation.relation_type,
                    'strength': relation.strength,
                    'frequency': relation.frequency
                })
        
        # ç»Ÿè®¡ä¿¡æ¯
        graph_data['statistics'] = {
            'total_users': len(self.user_profiles),
            'total_relations': sum(len(relations) for relations in self.social_graph.values()),
            'nickname_mappings': len(self.nickname_mapping)
        }
        
        return graph_data
