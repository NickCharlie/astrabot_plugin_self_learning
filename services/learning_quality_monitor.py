"""
å­¦ä¹ è´¨é‡ç›‘æ§æœåŠ¡ - ç›‘æ§å­¦ä¹ æ•ˆæœï¼Œé˜²æ­¢äººæ ¼å´©å
"""
import json
import time
import re # ç§»åŠ¨åˆ°æ–‡ä»¶é¡¶éƒ¨
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

from astrbot.api import logger
from astrbot.api.star import Context

from ..config import PluginConfig
from ..exceptions import StyleAnalysisError


@dataclass
class PersonaMetrics:
    """äººæ ¼æŒ‡æ ‡"""
    consistency_score: float = 0.0      # ä¸€è‡´æ€§å¾—åˆ†
    style_stability: float = 0.0        # é£æ ¼ç¨³å®šæ€§
    vocabulary_diversity: float = 0.0   # è¯æ±‡å¤šæ ·æ€§
    emotional_balance: float = 0.0      # æƒ…æ„Ÿå¹³è¡¡æ€§
    coherence_score: float = 0.0        # é€»è¾‘è¿è´¯æ€§


@dataclass
class LearningAlert:
    """å­¦ä¹ è­¦æŠ¥"""
    alert_type: str
    severity: str  # low, medium, high, critical
    message: str
    timestamp: str
    metrics: Dict[str, float]
    suggestions: List[str]


class LearningQualityMonitor:
    """å­¦ä¹ è´¨é‡ç›‘æ§å™¨"""
    
    def __init__(self, config: PluginConfig, context: Context, llm_client):
        self.config = config
        self.context = context
        self._llm_client = llm_client # æ·»åŠ  llm_client
        
        # ç›‘æ§é˜ˆå€¼
        self.consistency_threshold = 0.7    # ä¸€è‡´æ€§é˜ˆå€¼
        self.stability_threshold = 0.6      # ç¨³å®šæ€§é˜ˆå€¼
        self.drift_threshold = 0.3          # é£æ ¼åç§»é˜ˆå€¼
        
        # å†å²æŒ‡æ ‡å­˜å‚¨
        self.historical_metrics: List[PersonaMetrics] = []
        self.alerts_history: List[LearningAlert] = []
        
        logger.info("å­¦ä¹ è´¨é‡ç›‘æ§æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def evaluate_learning_batch(self, 
                                    original_persona: Dict[str, Any],
                                    updated_persona: Dict[str, Any],
                                    learning_messages: List[Dict[str, Any]]) -> PersonaMetrics:
        """è¯„ä¼°å­¦ä¹ æ‰¹æ¬¡è´¨é‡"""
        try:
            # è®¡ç®—å„é¡¹æŒ‡æ ‡
            consistency_score = await self._calculate_consistency(
                original_persona, updated_persona
            )
            
            style_stability = await self._calculate_style_stability(
                learning_messages
            )
            
            vocabulary_diversity = await self._calculate_vocabulary_diversity(
                learning_messages
            )
            
            emotional_balance = await self._calculate_emotional_balance(
                learning_messages
            )
            
            coherence_score = await self._calculate_coherence(
                updated_persona
            )
            
            metrics = PersonaMetrics(
                consistency_score=consistency_score,
                style_stability=style_stability,
                vocabulary_diversity=vocabulary_diversity,
                emotional_balance=emotional_balance,
                coherence_score=coherence_score
            )
            
            # å­˜å‚¨å†å²æŒ‡æ ‡
            self.historical_metrics.append(metrics)
            
            # è°ƒæ•´é˜ˆå€¼
            await self.adjust_thresholds_based_on_history()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘å‡ºè­¦æŠ¥
            await self._check_quality_alerts(metrics)
            
            return metrics
            
        except Exception as e:
            logger.error(f"å­¦ä¹ è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            raise StyleAnalysisError(f"å­¦ä¹ è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")

    async def _calculate_consistency(self, 
                                   original_persona: Dict[str, Any],
                                   updated_persona: Dict[str, Any]) -> float:
        """è®¡ç®—äººæ ¼ä¸€è‡´æ€§å¾—åˆ†"""
        try:
            if not self._llm_client:
                logger.warning("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMè®¡ç®—ä¸€è‡´æ€§ï¼Œä½¿ç”¨é»˜è®¤å€¼ã€‚")
                return 0.5
            
            prompt = f"""
                è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªäººæ ¼è®¾å®šçš„ä¸€è‡´æ€§ç¨‹åº¦ï¼Œç»™å‡º0-1ä¹‹é—´çš„å¾—åˆ†ï¼š

                åŸå§‹äººæ ¼ï¼š
                {original_persona.get('prompt', '')}

                æ›´æ–°äººæ ¼ï¼š
                {updated_persona.get('prompt', '')}

                è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ä¸€è‡´æ€§ï¼š
                1. æ ¸å¿ƒæ€§æ ¼ç‰¹å¾æ˜¯å¦ä¿æŒ
                2. è¯­è¨€é£æ ¼æ˜¯å¦è¿è´¯
                3. ä»·å€¼è§‚æ˜¯å¦ä¸€è‡´
                4. è¡Œä¸ºæ¨¡å¼æ˜¯å¦ç¨³å®š

                ç›´æ¥è¿”å›ä¸€ä¸ª0-1ä¹‹é—´çš„æ•°å€¼ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡Šã€‚
                """
            
            # è°ƒç”¨æ¨¡å‹åˆ†æ
            response = await self._llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.refine_api_url,
                api_key=self.config.refine_api_key,
                model_name=self.config.refine_model_name
            )
            
            # å°è¯•æå–æ•°å€¼
            numbers = re.findall(r'0\.\d+|1\.0|0', response)
            if numbers:
                return min(float(numbers[0]), 1.0) # ä¿®æ”¹ä¸º float(numbers[0])
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"ä¸€è‡´æ€§è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 0.5

    async def _calculate_style_stability(self, messages: List[Dict[str, Any]]) -> float:
        """è®¡ç®—é£æ ¼ç¨³å®šæ€§"""
        if len(messages) < 2:
            return 1.0
            
        try:
            # åˆ†ææ¶ˆæ¯çš„é£æ ¼ç‰¹å¾
            style_features = []
            for msg in messages:
                features = {
                    'length': len(msg['message']),
                    'punctuation_ratio': self._get_punctuation_ratio(msg['message']),
                    'emoji_count': self._count_emoji(msg['message']),
                    'question_count': msg['message'].count('?') + msg['message'].count('ï¼Ÿ'),
                    'exclamation_count': msg['message'].count('!') + msg['message'].count('ï¼')
                }
                style_features.append(features)
            
            # è®¡ç®—ç‰¹å¾æ–¹å·®ï¼ˆç¨³å®šæ€§ä¸æ–¹å·®æˆåæ¯”ï¼‰
            variance_scores = []
            for feature in ['length', 'punctuation_ratio', 'emoji_count']:
                values = [f[feature] for f in style_features]
                if len(values) > 1:
                    mean_val = sum(values) / len(values)
                    variance = sum((x - mean_val) ** 2 for x in values) / len(values)
                    # å½’ä¸€åŒ–æ–¹å·®å¾—åˆ†ï¼ˆè¶Šå°è¶Šç¨³å®šï¼‰
                    normalized_variance = min(variance / (mean_val + 1), 1.0)
                    variance_scores.append(1.0 - normalized_variance)
            
            return sum(variance_scores) / len(variance_scores) if variance_scores else 0.5
            
        except Exception as e:
            logger.warning(f"é£æ ¼ç¨³å®šæ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.5

    async def _calculate_vocabulary_diversity(self, messages: List[Dict[str, Any]]) -> float:
        """è®¡ç®—è¯æ±‡å¤šæ ·æ€§"""
        try:
            all_text = ' '.join([msg['message'] for msg in messages])
            words = all_text.split()
            
            if len(words) == 0:
                return 0.0
            
            unique_words = set(words)
            diversity_ratio = len(unique_words) / len(words)
            
            # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
            return min(diversity_ratio * 2, 1.0)
            
        except Exception as e:
            logger.warning(f"è¯æ±‡å¤šæ ·æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.5

    async def _calculate_emotional_balance(self, messages: List[Dict[str, Any]]) -> float:
        """ä½¿ç”¨LLMè®¡ç®—æƒ…æ„Ÿå¹³è¡¡æ€§"""
        if not self._llm_client:
            logger.warning("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨LLMè®¡ç®—æƒ…æ„Ÿå¹³è¡¡æ€§ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•ã€‚")
            return self._simple_emotional_balance(messages)

        messages_text = "\n".join([msg['message'] for msg in messages])
        
        prompt = f"""
                è¯·åˆ†æä»¥ä¸‹æ¶ˆæ¯é›†åˆçš„æƒ…æ„Ÿå¹³è¡¡æ€§ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç§¯æå’Œæ¶ˆææƒ…æ„Ÿçš„ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ0-1ä¹‹é—´ï¼‰ã€‚

                æ¶ˆæ¯é›†åˆï¼š
                {messages_text}

                è¯·åªè¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¾‹å¦‚ï¼š
                {{
                    "ç§¯æ": 0.8,
                    "æ¶ˆæ": 0.2
                }}
                """
        try:
            response = await self._llm_client.chat_completion(
                prompt=prompt,
                api_url=self.config.refine_api_url,
                api_key=self.config.refine_api_key,
                model_name=self.config.refine_model_name
            )
            if response and response.text():
                try:
                    emotional_scores = json.loads(response.text().strip())
                    # ç¡®ä¿æ‰€æœ‰åˆ†æ•°éƒ½åœ¨0-1ä¹‹é—´
                    for key, value in emotional_scores.items():
                        emotional_scores[key] = max(0.0, min(float(value), 1.0))
                    
                    # è®¡ç®—æƒ…æ„Ÿå¹³è¡¡æ€§ï¼šç§¯ææƒ…æ„Ÿå‡å»æ¶ˆææƒ…æ„Ÿï¼Œå†è°ƒæ•´åˆ°0-1èŒƒå›´
                    positive_score = emotional_scores.get("ç§¯æ", 0.5)
                    negative_score = emotional_scores.get("æ¶ˆæ", 0.5)
                    balance_score = (positive_score - negative_score + 1.0) / 2.0  # è½¬æ¢åˆ°0-1èŒƒå›´
                    return max(0.0, min(balance_score, 1.0))
                except json.JSONDecodeError:
                    logger.warning(f"LLMå“åº”JSONè§£æå¤±è´¥ï¼Œè¿”å›ç®€åŒ–æƒ…æ„Ÿå¹³è¡¡æ€§åˆ†æã€‚å“åº”å†…å®¹: {response.text()}")
                    return self._simple_emotional_balance(messages)
            return self._simple_emotional_balance(messages)
        except Exception as e:
            logger.warning(f"LLMæƒ…æ„Ÿå¹³è¡¡æ€§è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•: {e}")
            return self._simple_emotional_balance(messages)

    def _simple_emotional_balance(self, messages: List[Dict[str, Any]]) -> float:
        """ç®€åŒ–çš„æƒ…æ„Ÿå¹³è¡¡æ€§è®¡ç®—ï¼ˆå¤‡ç”¨ï¼‰"""
        positive_words = ['å¥½', 'æ£’', 'èµ', 'å–œæ¬¢', 'å¼€å¿ƒ', 'é«˜å…´', 'å“ˆå“ˆ']
        negative_words = ['ä¸', 'æ²¡', 'å', 'çƒ¦', 'è®¨åŒ', 'ç”Ÿæ°”', 'éš¾è¿‡']
        
        pos_count = 0
        neg_count = 0
        
        for msg in messages:
            text = msg['message']
            for word in positive_words:
                pos_count += text.count(word)
            for word in negative_words:
                neg_count += text.count(word)
        
        total_emotional = pos_count + neg_count
        if total_emotional == 0:
            return 0.8  # ä¸­æ€§æƒ…æ„Ÿ
        
        # è®¡ç®—å¹³è¡¡æ€§ï¼ˆè¶Šæ¥è¿‘0.5è¶Šå¹³è¡¡ï¼‰
        pos_ratio = pos_count / total_emotional
        balance_score = 1.0 - abs(pos_ratio - 0.5) * 2
        
        return balance_score

    async def _calculate_coherence(self, persona: Dict[str, Any]) -> float:
        """è®¡ç®—é€»è¾‘è¿è´¯æ€§"""
        try:
            prompt_text = persona.get('prompt', '')
            if not prompt_text:
                return 0.0
            
            # ç®€å•çš„è¿è´¯æ€§æ£€æŸ¥
            sentences = prompt_text.split('ã€‚')
            if len(sentences) < 2:
                return 0.8
            
            # æ£€æŸ¥å¥å­é•¿åº¦ä¸€è‡´æ€§å’Œç»“æ„å®Œæ•´æ€§
            sentence_lengths = [len(s.strip()) for s in sentences if s.strip()]
            if not sentence_lengths:
                return 0.0
            
            avg_length = sum(sentence_lengths) / len(sentence_lengths)
            length_variance = sum((l - avg_length) ** 2 for l in sentence_lengths) / len(sentence_lengths)
            
            # å½’ä¸€åŒ–è¿è´¯æ€§å¾—åˆ†
            coherence = max(0.0, 1.0 - length_variance / (avg_length + 1))
            
            return min(coherence, 1.0)
            
        except Exception as e:
            logger.warning(f"è¿è´¯æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.5

    async def _check_quality_alerts(self, metrics: PersonaMetrics):
        """æ£€æŸ¥è´¨é‡è­¦æŠ¥"""
        alerts = []
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        if metrics.consistency_score < self.consistency_threshold:
            alerts.append(LearningAlert(
                alert_type="consistency",
                severity="high" if metrics.consistency_score < 0.5 else "medium",
                message=f"äººæ ¼ä¸€è‡´æ€§å¾—åˆ†è¿‡ä½: {metrics.consistency_score:.3f}",
                timestamp=datetime.now().isoformat(),
                metrics={'consistency_score': metrics.consistency_score},
                suggestions=["å»ºè®®äººå·¥å®¡æ ¸äººæ ¼å˜åŒ–", "è€ƒè™‘å›æ»šåˆ°ä¹‹å‰çš„äººæ ¼ç‰ˆæœ¬"]
            ))
        
        # ç¨³å®šæ€§æ£€æŸ¥
        if metrics.style_stability < self.stability_threshold:
            alerts.append(LearningAlert(
                alert_type="stability",
                severity="medium",
                message=f"é£æ ¼ç¨³å®šæ€§ä¸è¶³: {metrics.style_stability:.3f}",
                timestamp=datetime.now().isoformat(),
                metrics={'style_stability': metrics.style_stability},
                suggestions=["å¢åŠ è®­ç»ƒæ•°æ®ä¸€è‡´æ€§", "è°ƒæ•´å­¦ä¹ ç‡"]
            ))
        
        # é£æ ¼åç§»æ£€æŸ¥
        if len(self.historical_metrics) >= 2:
            current_drift = self._calculate_style_drift(
                self.historical_metrics[-2], metrics
            )
            if current_drift > self.drift_threshold:
                alerts.append(LearningAlert(
                    alert_type="drift",
                    severity="critical" if current_drift > 0.5 else "high",
                    message=f"æ£€æµ‹åˆ°æ˜¾è‘—é£æ ¼åç§»: {current_drift:.3f}",
                    timestamp=datetime.now().isoformat(),
                    metrics={'style_drift': current_drift},
                    suggestions=["ç«‹å³æš‚åœè‡ªåŠ¨å­¦ä¹ ", "äººå·¥å®¡æ ¸å­¦ä¹ æ•°æ®", "è€ƒè™‘é‡ç½®äººæ ¼"]
                ))
        
        # å­˜å‚¨è­¦æŠ¥
        self.alerts_history.extend(alerts)
        
        # è®°å½•è­¦æŠ¥
        for alert in alerts:
            logger.warning(f"å­¦ä¹ è´¨é‡è­¦æŠ¥ [{alert.severity}]: {alert.message}")

    def _calculate_style_drift(self, prev_metrics: PersonaMetrics, curr_metrics: PersonaMetrics) -> float:
        """è®¡ç®—é£æ ¼åç§»ç¨‹åº¦"""
        # è®¡ç®—å…³é”®æŒ‡æ ‡çš„å˜åŒ–å¹…åº¦
        consistency_drift = abs(curr_metrics.consistency_score - prev_metrics.consistency_score)
        stability_drift = abs(curr_metrics.style_stability - prev_metrics.style_stability)
        diversity_drift = abs(curr_metrics.vocabulary_diversity - prev_metrics.vocabulary_diversity)
        
        # åŠ æƒå¹³å‡åç§»
        weighted_drift = (
            consistency_drift * 0.4 +
            stability_drift * 0.3 +
            diversity_drift * 0.3
        )
        
        return weighted_drift

    def _get_punctuation_ratio(self, text: str) -> float:
        """è·å–æ ‡ç‚¹ç¬¦å·æ¯”ä¾‹"""
        punctuation = 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€""''()ï¼ˆï¼‰ã€ã€‘'
        punct_count = sum(1 for char in text if char in punctuation)
        return punct_count / len(text) if text else 0.0

    def _count_emoji(self, text: str) -> int:
        """ç»Ÿè®¡è¡¨æƒ…ç¬¦å·æ•°é‡"""
        # ç®€å•çš„è¡¨æƒ…ç¬¦å·æ£€æµ‹
        emoji_patterns = ['ğŸ˜€', 'ğŸ˜‚', 'ğŸ˜Š', 'ğŸ¤”', 'ğŸ‘', 'â¤ï¸', 'ğŸ‰']
        count = 0
        for emoji in emoji_patterns:
            count += text.count(emoji)
        return count

    async def get_quality_report(self) -> Dict[str, Any]:
        """è·å–è´¨é‡æŠ¥å‘Š"""
        if not self.historical_metrics:
            return {"error": "æš‚æ— å†å²æ•°æ®"}
        
        latest_metrics = self.historical_metrics[-1]
        
        # è®¡ç®—è¶‹åŠ¿
        trends = {}
        if len(self.historical_metrics) >= 2:
            prev_metrics = self.historical_metrics[-2]
            trends = {
                'consistency_trend': latest_metrics.consistency_score - prev_metrics.consistency_score,
                'stability_trend': latest_metrics.style_stability - prev_metrics.style_stability,
                'diversity_trend': latest_metrics.vocabulary_diversity - prev_metrics.vocabulary_diversity
            }
        
        # è·å–æœ€è¿‘çš„è­¦æŠ¥
        recent_alerts = [
            alert for alert in self.alerts_history
            if datetime.fromisoformat(alert.timestamp) > datetime.now() - timedelta(hours=24)
        ]
        
        return {
            'current_metrics': {
                'consistency_score': latest_metrics.consistency_score,
                'style_stability': latest_metrics.style_stability,
                'vocabulary_diversity': latest_metrics.vocabulary_diversity,
                'emotional_balance': latest_metrics.emotional_balance,
                'coherence_score': latest_metrics.coherence_score
            },
            'trends': trends,
            'recent_alerts': len(recent_alerts),
            'alert_summary': {
                'critical': len([a for a in recent_alerts if a.severity == 'critical']),
                'high': len([a for a in recent_alerts if a.severity == 'high']),
                'medium': len([a for a in recent_alerts if a.severity == 'medium'])
            },
            'recommendations': self._generate_recommendations(latest_metrics, recent_alerts)
        }

    def _generate_recommendations(self, metrics: PersonaMetrics, alerts: List[LearningAlert]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if metrics.consistency_score < 0.7:
            recommendations.append("å»ºè®®å¢åŠ äººæ ¼ä¸€è‡´æ€§æ£€æŸ¥")
        
        if metrics.style_stability < 0.6:
            recommendations.append("å»ºè®®è°ƒæ•´å­¦ä¹ æ•°æ®ç­›é€‰æ ‡å‡†")
        
        if len(alerts) > 5:
            recommendations.append("è­¦æŠ¥é¢‘ç¹ï¼Œå»ºè®®äººå·¥ä»‹å…¥å®¡æ ¸")
        
        if not recommendations:
            recommendations.append("å­¦ä¹ è´¨é‡è‰¯å¥½ï¼Œå¯ç»§ç»­è‡ªåŠ¨å­¦ä¹ ")
        
        return recommendations

    async def should_pause_learning(self) -> tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æš‚åœå­¦ä¹ """
        if not self.historical_metrics:
            return False, ""
        
        latest_metrics = self.historical_metrics[-1]
        
        # æ£€æŸ¥å…³é”®æŒ‡æ ‡
        if latest_metrics.consistency_score < 0.4:
            return True, "äººæ ¼ä¸€è‡´æ€§ä¸¥é‡ä¸‹é™"
        
        # æ£€æŸ¥æœ€è¿‘çš„ä¸¥é‡è­¦æŠ¥
        recent_critical_alerts = [
            alert for alert in self.alerts_history
            if (alert.severity in ['critical', 'high'] and 
                datetime.fromisoformat(alert.timestamp) > datetime.now() - timedelta(hours=1))
        ]
        
        if len(recent_critical_alerts) >= 2:
            return True, "æ£€æµ‹åˆ°å¤šä¸ªä¸¥é‡è´¨é‡é—®é¢˜"
        
        return False, ""
